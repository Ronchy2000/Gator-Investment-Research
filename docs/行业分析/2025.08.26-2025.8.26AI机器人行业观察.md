# 2025.8.26AI机器人行业观察

- 分类: 行业分析
- 日期: 2025.08.26
- 文章ID: 501
- 来源: http://h5.2025eyp.com/articles/501

---

> 智元推出机器人世界模型平台 Genie Envisioner，智谱上线 GLM-4.5V 视觉推理模型

### **2.1 智元推出机器人世界模型平台 Genie Envisioner**

1. **发布时间与背景**：智元机器人于 2025 年 7 月 27 日在 WAIC 2025 “智启具身论坛” 发布行业首个动作驱动世界模型开源平台 Genie Envisioner（简称 GE），8 月 14 日进一步推出面向真实世界机器人操控的统一世界模型平台。

2. **核心突破**：颠覆传统机器人学习 “数据 - 训练 - 评估” 割裂的流水线模式，构建以视频生成为核心的闭环架构，使机器人能在同一世界模型中完成从视觉感知到动作执行的端到端推理与执行；采用视觉中心的世界建模范式，直接在视觉空间建模机器人与环境交互动态，完整保留操控过程空间结构和时序演化信息。

3. **优势表现**：具备高效跨本体泛化能力，GE-Act 仅需 1 小时约 250 个演示的遥操作数据即可在新机器人平台实现高质量任务执行；拥有长时序任务精确执行能力，折叠纸盒等超长步骤任务成功率达 76%，优于专门优化的 π0 模型（48%）。

4. **技术架构**：由 GE-Base、GE-Act、GE-Sim 三大核心组件构成。

· **GE-Base**：多视角视频世界基础模型，采用自回归视频生成框架，通过三路视角输入保持空间一致性，利用稀疏记忆机制增强长时序推理能力；基于 AgiBot-World-Beta 数据集的 3000 小时超 100 万条真机数据，用 32 块 A100 GPU 耗时约 10 天完成训练。

· **GE-Act**：160M 参数轻量级动作解码器，采用与 GE-Base 平行的流匹配设计，异步推理模式实现实时控制，视频 DiT 以 5Hz 运行，动作模型以 30Hz 运行，可在 RTX 4090 GPU 上以 200 毫秒完成 54 步动作推理。

· **GE-Sim**：层次化动作条件仿真器，通过 Pose2Image 条件和运动向量机制将低层控制指令转换为精确视觉预测，支持闭环策略评估和大规模数据生成。

5. **实际应用**：搭载 GE-Act 的机器人可流畅完成制作三明治、倒茶、擦桌面、使用微波炉加热、流水线装箱等任务，成功率超行业平均水平；工业场景中，机器人能基于 GE 预测能力提前模拟装配过程并优化策略，实现从固定轨迹到自主决策的跨越。

6. **开源与扩展计划**：智元机器人将开源全部代码、预训练模型和评测工具，计划未来扩展更多传感器模态以支持全身移动与人机协作；开发 EWMBench 评测套件，从场景一致性、轨迹精度等多维度评估世界模型质量，GE-Base 在与 Kling、Hailuo 等先进模型对比中关键指标均最优。

### **2.2 智谱上线 GLM-4.5V 视觉推理模型**

1. **发布时间与规模**：智谱 AI 于 2025 年 8 月 11 日发布并开源新一代视觉推理模型 GLM-4.5V，总参数 1060 亿、激活参数 120 亿，为全球 100B 级效果最佳的开源视觉推理模型，同步在 GitHub、Hugging Face 及魔搭社区开放下载。

2. **基础与性能**：基于旗舰文本基座 GLM-4.5-Air 构建，延续 GLM-4.1V-Thinking 技术路线，在 41 项公开视觉多模态基准测试中全面达到同级别开源模型 SOTA 性能，涵盖图像、视频、文档理解及 GUI Agent 等核心任务场景。

3. **技术架构**：采用视觉编码器、MLP 适配器与语言解码器三模块设计，引入三维旋转位置编码（3D-RoPE）和双三次插值机制，增强对多模态信息中三维空间关系的感知能力及对高分辨率、极端宽高比图像的适应性；支持 64K 多模态长上下文，结合三维卷积优化视频处理效率，可同步解析图像与视频输入。

4. **训练策略**：采用三阶段优化流程，预训练阶段利用大规模图文交错多模态语料强化基础理解能力；监督微调阶段引入显式 “思维链” 样本提升因果推理深度；强化学习阶段通过多领域奖励系统结合 RLVR 与 RLHF 技术，在 STEM 问题、多模态定位等任务实现突破。

5. **实际应用**：具备前端复刻功能，仅凭网页截图或交互视频可生成结构化 HTML/CSS/JavaScript 代码，精准还原布局逻辑与交互意图；内置 GUI Agent 能力，可识别电商页面折扣信息并计算最优方案；同步开源桌面助手应用，支持实时截屏录屏交互，处理代码辅助、游戏解答等多样化视觉任务。

6. **商业化部署**：API 调用价格低至输入 2 元 / 百万 tokens、输出 6 元 / 百万 tokens，响应速度达 60-80 tokens/s；为开发者提供 2000 万 tokens 免费资源包，加速多模态应用落地。

### **2.3 字节 Seed 团队开源 VeOmni 全模态训练框架**

1. **发布时间与意义**：字节跳动 Seed 团队于 2025 年 8 月 14 日开源全模态 PyTorch 原生训练框架 VeOmni，标志多模态大模型训练进入 “低摩擦时代”。

2. **核心优势**：通过 “以模型为中心” 的分布式设计理念，解决传统训练方法在工程复杂度、扩展性和效率上的瓶颈，将全模态研发周期从数周缩短至几天，工程耗时降低 90% 以上；在 128 卡 GPU 集群上实现 300 亿参数 MoE 模型 2800 tokens/sec/GPU 的吞吐量，支持高达 160K 超长上下文序列训练。

3. **技术突破**：彻底解耦模型定义与分布式并行逻辑，构建模块化、可组合训练范式；通过 DeviceMesh 抽象层统一管理并行状态，将模型组件转化为 “计算模块”，通信逻辑由框架自动处理，研究者仅需通过 API 声明并行维度即可实现复杂组合策略，无需侵入式修改模型代码。

4. **效率优化**：在并行策略上，引入异步序列并行（Async-Ulysses），将 All-to-All 通信与 Attention 计算重叠，64K 序列训练 MFU（模型浮点利用率）达 43.98%；针对 MoE 模型开发 COMET 技术，实现细粒度计算 - 通信重叠；系统级优化方面，动态批处理技术配合 FlashAttention 减少填充浪费，ROI 驱动的算子级重计算策略提升显存回收效率 22 倍，ByteCheck 系统支持千卡集群中断恢复时间缩短 90%。

5. **内部应用与测试表现**：多模态智能体 UI-TARS-1.5 借助其序列并行能力解决 > 128K 长序列数据显存瓶颈；同传模型 Seed LiveInterpret 2.0 利用框架集成的轨迹蒸馏与分布匹配蒸馏（DMD）技术，将推理步数压缩至 4-8 步，成本降低 70%；标准化测试中，72B 参数模型在 128 卡集群上实现 96K 序列训练，MFU 达 54.82%，16K 序列场景吞吐量较 TorchTitan 提升 29.82%（532 vs 394 tokens/sec），64K 序列时 VeOmni 稳定运行而 TorchTitan 出现 OOM。

6. **开源价值**：填补工业级任意模态训练方案技术空白，轻量级全模态接口遵循 HuggingFace 规范，允许快速集成各类组件，GitHub 仓库提供桌面助手应用，支持实时截屏录屏交互，加速 GUI Agent 开发，降低中小型企业进入门槛，推动学术研究从工程调优转向算法创新。

### **2.4 昆仑万维开源多模态框架 Skywork UniPic 2.0**

1. **发布时间与定位**：昆仑万维于 2025 年 8 月 13 日在 SkyWork AI 技术发布周开源 Skywork UniPic 2.0，是首次在单一模型中深度融合图像理解、文本到图像生成（T2I）和图像编辑（I2I）三大核心能力的统一多模态框架。

2. **基础与优势**：基于 2B 参数的 SD3.5-Medium 架构，通过创新的渐进式双任务强化策略和轻量化设计，实现生成质量与部署效率双重突破，性能超越多个 12B 以上参数的同类模型，成为开源多模态领域新标杆。

3. **技术架构**：采用三模块协同设计，构建从理解到生成再到编辑的端到端闭环。

· **生图编辑模块**：改造 SD3.5-Medium 架构，使其支持文本与图像混合输入，文本经编码器生成指令表示，参考图像经 VAE 编码为潜变量并映射为上下文 token，与目标图像噪声 token 拼接成统一序列，利用位置编码区分不同片段；基于 600 万高质量生图样本和 500 万编辑样本的社区开源数据训练。

· **统一模型能力模块**：冻结生图编辑部分，引入 Qwen2.5-VL-7B 多模态模型和轻量连接器进行特征对齐，训练分两阶段，先预训练连接器实现多模态特征空间匹配，再联合微调连接器与生图模块。

4. **性能突破核心**：生图编辑后训练阶段采用 Flow-GRPO 渐进式双任务强化策略，先专项强化图像编辑任务，再优化文生图任务语义理解，避免任务间干扰并产生协同增益；构建行业首个图像编辑专用奖励模型 Skywork-EditReward，以 Qwen2.5-VL-7B 为骨架，经 33.3 万条编辑样本训练并由 GPT-4.1 标注校准。

5. **评测表现**：基础版本 UniPic2-SD3.5M-Kontext 在 GenEval 生图评估中得 0.89 分，超越 12B 参数的 Flux.dev（0.84 分）；编辑任务上 GEdit-EN 得分 6.59，领先 12B 的 Flux-Kontext（6.26 分）；扩展为统一架构的 UniPic2-Metaquery 后，编辑分数提升至 7.10，逼近闭源的 GPT-4o（7.53 分），理解能力在 MMBench 等基准测试中达 83.5 分，与 19B 参数的 UniWorld-V1 相当。

6. **实际应用与开源**：可在电商、游戏等领域提升效率，如电商团队输入商品图片与指令可直接生成多版营销海报，游戏开发者通过文字描述快速迭代角色原画；可在 RTX 4090 消费级显卡运行，生成复杂图像仅需几秒；GitHub 仓库提供桌面助手应用，支持实时截屏交互，开发者仅需实现标准接口即可集成自定义视觉组件。

## **三、企业动态**

### **3.1 阿里发布通义 Wan2.2-I2V-Flash 模型**

1. **发布时间与定位**：阿里通义大模型于 2025 年 8 月 11 日发布 Wan2.2-I2V-Flash 模型，标志图生视频技术进入 “轻快” 时代，是通义万相 2.2 系列最新成员。

2. **性能提升**：在前代 Wan2.1 基础上实现 12 倍推理速度跃升，API 调用价格降至 0.1 元 / 秒，抽卡成功率提升 123%，为目前性价比最高的电影级视频生成解决方案。

3. **技术架构**：延续通义万相 2.2 系列首创的 MoE（混合专家）架构，总参数量 27B，激活参数 14B，高噪声专家模型负责视频整体框架构建，低噪专家模型专注细节优化；采用电影美学控制系统，将光影、色彩、构图等专业电影元素封装为 60 多个可调节参数，用户可精准调整视频风格。

4. **技术创新**：采用动态稀疏激活机制，根据输入图像与文本指令自动分配计算资源；优化的指令遵循系统支持特效提示词直出与运镜精准控制；异步流水线设计实现生成过程多阶段重叠，视频 DiT 与动作解码器并行运行，5 秒视频端到端生成耗时从数分钟压缩至秒级。

5. **实际应用**：电商平台可通过 API 快速生成商品展示视频，教育机构能将历史图片转换为动态场景；阿里云百炼平台提供异步调用接口，支持 480P 与 720P 分辨率输出，开发者可通过 DashScope SDK 实现 Python 或 Java 环境集成，动态批处理技术可同时处理数百个生成请求；强化对极端宽高比图像的适配能力，生成视频自动保持原始比例并智能补全。

6. **与开源版本对比**：与开源版本 Wan2.2-I2V-A14B 参数量相同，通过量化压缩与算子优化实现消费级硬件可部署性，在 RTX 4090 显卡上生成 720P 视频仅需 200 毫秒推理时间，显存占用降低 40%；支持种子锁定与负向提示词功能，提升内容可控性。

7. **生态影响**：开源版本吸引超 3 万开发者下载，衍生动漫分镜生成、工业流程模拟等创新应用，随着在阿里云全球 21 个地域规模化部署，技术红利加速渗透至广告、教育、社交等领域。

### **3.2 昆仑万维上线音频模型 Mureka V7.5，并推 MoE-TTS 语音合成框架**

1. **发布时间与意义**：昆仑万维于 2025 年 8 月 15 日在 SkyWork AI 技术发布周推出音频生成模型 Mureka V7.5 及 MoE-TTS 语音合成框架，标志中文 AI 音乐创作与语音合成技术迈入新阶段，为多模态内容创作提供完整技术闭环。

2. **Mureka V7.5 核心突破**：专注中文音乐艺术神韵与情感表达，捕捉从传统民歌、戏曲到当代流行乐的语义结构和情感走向。

· 优化自动语音识别技术（ASR），反向建模真实演唱中的气息运用、情感起伏和唱法细节。

· 将人类主观听感评分机制引入训练目标，规避机械感音色特征。

· 构建跨文化语境理解模块，使生成作品准确传达歌词语义并契合目标审美与文化背景。

3. **Mureka V7.5 评测表现**：在中文歌曲质量与提示契合度两项主观评测中，分别以 34.8% 和 45.2% 的得票率超越 Suno、Udio 等国际主流模型。

4. **MoE-TTS 特点**：全球首个基于混合专家架构的角色描述语音合成框架，摒弃传统标签式模板控制，采用自然语言驱动的开放描述系统，用户可通过复杂描述精准控制声音特征。

· 技术设计：预训练大语言模型（LLM）解析自然语言语义并生成高维表达向量，多个语音专家模块并行建模风格、节奏、语气等维度，通过模态路由器动态聚合输出；冻结文本参数实现跨模态信息对齐，避免知识损失，提升对复杂修辞的泛化能力。

· 评测表现：在域内与域外描述测试集上，风格表现力贴合度与整体贴合度均优于 ElevenLabs、MiniMax 等闭源产品，尤其在处理复合角色设定时表现出色。

5. **协同效应**：Mureka V7.5 采用 MoE-TTS 作为人声生成引擎，使演唱音高准确且能根据歌词情感调整微观表现；MoE-TTS 通过 Mureka 积累的中文演唱数据优化专家模块，强化对声乐技巧的建模能力。

6. **商业化落地**：提供分层级创作工具链，简单模式支持自然语言描述生成完整歌曲，高级模式开放精细控制，音频编辑模块提供 DAW 级功能；MoE-TTS 规划集成至 Mureka-Speech 平台，服务于情绪播报、游戏语音包、无障碍阅读等场景，API 支持实时生成带特定文化特征的语音。

## **四、AI 行业洞察**

### **4.1 阿里国际站 Accio Agent 海外爆火**

1. **定位与发展**：阿里国际站 Accio Agent 是 B2B 领域 AI 应用创新产品，2024 年 11 月在欧洲 Web Summit 科技峰会首发，定位 “个人采购代理”，命名源自《哈利・波特》召唤咒语；截至 2025 年 8 月，企业用户量突破 200 万，将搜索到采购的转化率提升 20%-30%。

2. **技术架构**：采用多智能体动态任务分配机制，每次任务自动调度 5-10 个专业领域智能体协同工作；整合 Qwen2.5、DeepSeek 等推理模型，构建覆盖多领域的专业知识图谱；数据层整合阿里国际站 25 万商家及 3000 万家跨境贸易企业信息，通过多重交叉验证机制减少大模型幻觉。

3. **工作流革新**：实现端到端自动化闭环，用户提出需求后，30 秒内完成供应商匹配、市场趋势分析、采购策略生成、完整报告自动生成四阶段操作，将传统需数周的工作压缩至 10 分钟，适合中小企业快速响应市场机会。

4. **商业化落地场景**：

· 产品创新者：上传爆款产品图片可获得改款灵感并直连定制供应商，设计到打样周期从月级缩短至日级。

· 市场进入者：输入产品指令后，系统提供 ISO 认证厂商信息并基于趋势报告建议创新元素。

· 大宗采购商：夜间秒回功能自动捕获全球询盘，提升转化效率；依托 “Alibaba Guaranteed” 履约体系，降低跨境交易风险。
