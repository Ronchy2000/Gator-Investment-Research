# 2025.8.27AI 动态汇总

- 分类: 全部研报
- 日期: 2025.08.27
- 文章ID: 511
- 来源: http://h5.2025eyp.com/articles/511

---

> DeepSeek 线上模型升级至 V3.1，字节开源 360 亿参数 Seed-OSS 系列模型

## **AI 重点要闻**

### **2.1 DeepSeek 线上模型升级至 V3.1**

1. **发布背景**：DeepSeek 于 2025 年 8 月 21 日发布 V3.1 版本，官方称其为 “迈向 Agent（智能体）时代的第一步”，并非简单参数优化或小范围调整，而是多维度系统性革新。

2. **核心创新**

· **混合推理架构**：支持 “思考模式” 与 “非思考模式”，用户可通过官方 App 或网页端切换。非思考模式适用于简单任务实时交互，思考模式适用于代码生成、复杂决策等，依赖 Transformer 结构改造，动态激活注意力头，采用思维链压缩训练技术，减少冗余 token 输出。

· **上下文窗口扩展**：从 64K 扩展至 128K，基于 “两阶段长上下文扩展方法”，新增 8400 亿 tokens 训练数据，32K 和 128K 扩展阶段训练量分别增加 10 倍、3.3 倍，提升长上下文理解等能力。

3. **智能体能力**：通过后训练优化增强工具使用与任务自动化能力，在代码修复测评 SWE、命令行终端测试 Terminal-Bench、AiderPolyglot 多语言编程测试（得分 71.6%）、复杂搜索测试 browsecomp、多学科专家级难题测试 HLE 中表现优于前代模型。

4. **技术细节**：采用新参数精度格式 UE8M0 FP8 Scale，针对下一代国产芯片设计；升级分词器与 chat template，微调或 API 调用需参考新版说明文档。

5. **API 服务与商业化**

· API 接口区分非思考模式（deepseek-chat）和思考模式（deepseek-reasoner），均支持 128K 上下文；Beta 接口增加 strict 模式 Function Calling，支持 Anthropic API 格式。

· 2025 年 9 月 6 日起调整 API 价格，取消夜间优惠，输入缓存命中 0.5 元 / 百万 tokens、缓存未命中 4 元 / 百万 tokens，输出 12 元 / 百万 tokens。

6. **现存问题**：数学推理、逻辑分析等复杂任务进步有限，部分场景性能回退或中英文混杂输出；激进更新导致旧版 API 停用，影响商业应用稳定性。

### **2.2 字节开源 360 亿参数 Seed-OSS 系列模型**

1. **发布概况**：字节跳动 Seed 团队 2025 年 8 月 21 日开源，以 360 亿参数、原生 512K 超长上下文窗口为核心突破，采用 Apache-2.0 许可证，含基础模型（含 / 不含合成数据）与指令微调版三个版本，12 万亿 tokens 训练数据实现参数效率与性能平衡，强调研究友好性与商业实用性。

2. **技术架构**

· 采用稠密模型架构，64 层网络，隐藏层维度 5120，词汇表扩展至 155K；集成 GQA 机制，80 个查询头分组共享键值对；结合 RoPE 技术，原生支持 512K 上下文窗口，避免位置混淆。

· 训练阶段采用 RMSNorm 归一化与 SwiGLU 激活函数，12 万亿 tokens 训练数据量为同规模模型 80%，但在 MMLU-Pro、MATH 等基准测试中超越 Qwen3-32B 等竞品。

3. **核心机制与性能**

· “思考预算” 机制：用户可设定 512 整数倍 token 预算，模型实时反馈剩余资源并调整输出策略，如 AIME24 数学竞赛题 4K 预算正确率 91.7%，LiveCodeBench v6 编程测试 67.4 分刷新 SOTA；RULER（128K）测试 94.6 分，含合成数据基础模型在 MATH 任务得分 81.7，较纯净版高 20.4 分。

4. **部署与应用**：提供 Hugging Face 模型权重、vLLM 部署工具及 4 位 / 8 位量化方案，显存需求可压缩至 18GB（INT4）；在法律文档审查、代码库分析等场景有优势，如某律所 47 分钟完成千页并购协议风险扫描，效率提升 90%。

5. **现存问题**：36B 参数规模对显存要求高，限制边缘设备部署；部分复杂逻辑任务性能波动，多语言支持未覆盖所有小语种。

### **2.3 阿里推出开源多模态智能体 WebWatcher**

1. **发布意义**：阿里巴巴 2025 年 8 月 15 日发布，代表多模态 AI 研究重大突破，四大权威视觉问答基准测试超越 GPT-4o 等顶级闭源模型，在复杂推理、信息检索等方面表现卓越。

2. **核心能力**：同步解析图像与文本信息，自主调用多种工具链完成多步骤任务，整合网页浏览、图像搜索等工具，具备视觉理解、逻辑推理、知识调用、工具调度和自我验证五大核心能力，可处理长期追踪复杂课题。

3. **训练框架**：四阶段训练，先通过 CRAWLQA 模拟浏览权威网站构建数据，再轨迹采样构建网页操作链，接着监督微调学习基础工具调用与决策逻辑，最后强化学习优化长期推理能力；E2HQA 数据合成技术解决高质量数据稀缺问题。

4. **性能表现**：在 BrowseComp-VL、Humanity’s Last Exam-VL、LiveVQA、MMSearch 等测试中领先，如 Humanity’s Last Exam-VL Pass@1 分数 13.6% 高于 GPT-4o 的 9.8%，MMSearch Pass@1 得分 55.3% 高于 Gemini2.5-flash 的 43.9% 和 GPT-4o 的 24.1%。

5. **开源与影响**：开源完整技术栈，降低企业构建专业研究型 Agent 门槛，推动开源生态繁荣，标志深度研究能力不再被闭源巨头垄断，为多领域开辟新可能。

### **2.4 智谱发布全球首个手机 Agent：AutoGLM2.0**

1. **发布定位**：智谱 AI2025 年 8 月 20 日发布，被认为是全球首个真正意义上的手机通用智能体，通过创新云端架构和 “云手机 + 云电脑” 技术范式，实现 AI 从信息交互向行动执行跨越。

2. **核心架构**：“终端指令 - 云端执行 - 结果反馈” 闭环系统，为用户配备专属云端虚拟设备（安卓云手机、Ubuntu 云电脑），实现 “3A 原则”（全时运行、自主零干扰、全域连接），实测平均响应延迟 1.2 秒，操作精度 98.7%。

3. **技术驱动**：由 GLM-4.5（决策大脑，拆解模糊指令）与 GLM-4.5V（视觉执行器，识别 GUI 界面元素）协同驱动，通过端到端异步强化学习框架训练，任务成功率每周提升 1.2%，Device Use 基准测试中手机操作成功率 75.8%（AndroidWorld）、浏览器任务成功率 87.7%（WebVoyager），超越竞品。

4. **应用场景**：覆盖生活与办公，生活中如 “点 20 杯奶茶并用优惠券” 仅需 90 秒，效率提升 10 倍；办公中如自动生成行业报仅需 18 分钟，低于人工 1 小时 20 分钟，支持 40 余款高频应用及 20 余个办公平台。

5. **成本与安全**：单次任务成本降至 0.2 美元（约 1.5 元人民币），较传统 Agent 降低 93%；采用阿里云合作虚拟机镜像，用户数据仅保留时效性 token，敏感操作需二次确认。

6. **生态与影响**：开放 AutoGLM API 及开发者生态计划，可集成至智能硬件；预计 2026 年相关市场规模达 50 亿元；现存问题为跨应用稳定性、场景泛化能力需优化。

## **三、企业动态**

### **3.1 腾讯发布大模型训练库 WeChat-YATT**

1. **定位与基础**：基于 Megatron-Core 和 SGLang/vLLM 研发，专注强化学习（RL）和多模态模型训练，为研究者和开发者提供易扩展、简洁、高效、可靠的训练解决方案，已应用于微信内部业务，提升训练效率。

2. **核心创新**

· 解决多模态场景可扩展性瓶颈：引入并行控制器机制，多个控制器协同管理数据任务，分散系统压力，提升处理多模态、大数据量场景的可扩展性与稳定性，避免传统单一控制器的通信和内存瓶颈。

· 解决动态采样与生成式奖励计算效率短板：通过部分共存策略和异步交互机制，减轻模型切换损耗和长尾任务影响，提升训练吞吐量与资源利用率，支撑大规模 RLHF 任务迭代。

3. **资源放置模式**

· 全员共存模式：串行调度，Actor Rollouts、GenRM、Train 依次执行，组件完成后释放资源，适配常规训练场景，缩短资源空闲时间。

· 部分共存模式：适用于高频交互、动态采样复杂任务，Actor Rollouts 与 GenRM 独立部署异步交互，动态负载评估分配资源。

4. **技术特色**：并行控制器架构降低单节点内存消耗；针对生成式奖励模型场景提供不同资源放置策略；智能检查点策略支持异步保存与断点自动保存；实现数据并行组间负载均衡，减少资源空闲时间。

5. **实验效果**：GenRM 任务场景下，全员共存架构较开源框架 VeRL 整体平均训练时间缩短约 60%，各阶段训练速度快 50% 以上，因 WeChat-YATT 组件高效共享资源，VeRL 外置 GenRM 策略导致资源空闲。

### **3.2 通义千问推 Qwen-Image-Edit 图像编辑模型**

1. **基础与突破**：阿里巴巴通义千问团队 2025 年 8 月推出，基于 200 亿参数 Qwen-Image 基础模型训练，创新双重编码机制与 MMDiT 架构，实现语义与外观双重编辑能力深度融合。

2. **技术架构**：双路径输入，原始图像同时送入 Qwen2.5-VL 模型（提取高层语义特征）和 VAE 编码器（保留底层视觉细节），编辑时兼顾用户意图理解与视觉保真度。

3. **核心能力**

· 语义编辑：保持原始视觉语义，如原创 IP 编辑生成 MBTI 十六型人格表情包、视角合成支持物体旋转生成背面视图、风格迁移转换肖像艺术风格，依赖视觉概念抽象理解。

· 外观编辑：局部精确修改，非编辑区域不变，如添加指示牌生成倒影、删除微小物体，文本编辑保留字体字号，单字准确率 97.29%，中文支持复杂排版，解决传统模型文字问题。

· 链式编辑：迭代式交互，如修正书法作品错字，弥补单次编辑局限，适合专业修图，连续修改保持一致性，但对特殊字体识别有提升空间。

4. **性能与部署**：公开基准测试 SOTA，中英文场景综合评分分别 7.56、7.52，超越 GPT Image1；Apache 2.0 开源协议允许商业应用，Hugging Face 发布 60GB 完整模型权重；基础运行需 8GB 显存，专业使用推荐 RTX 4090/5090 显卡，未来将推 fp8 量化版本。

5. **应用场景**：重塑设计流程，电商批量修改海报、教育修正教材插图、影视优化资产开发，未完全替代专业工具，但推动创作团队结构性调整。

## **四、AI 行业洞察**

### **4.1 Sierra AI 创始人称 AI 市场分三赛道：前沿基础模型、AI 工具链和应用型 Agent**

1. **前沿基础模型赛道**

· 竞争焦点：大模型算法创新与算力规模，美国科技巨头如 OpenAI、Anthropic 凭借先发优势和算力投入领先，推动参数规模、多模态能力、推理效率突破。

· 商业模式：高度依赖资本投入，技术壁垒高，面临模型同质化和开源替代挑战；如 Anthropic 2025 年以 1700 亿美元估值融资，创 AI 领域纪录。

2. **AI 工具链赛道**

· 定位：提供大模型研发和应用所需开发工具、优化框架、部署环境，涵盖训练框架、推理加速库、提示词工程平台等。

· 价值与模式：降低 AI 应用开发门槛，提升生态开发效率，商业模式为开发者订阅或企业许可，随 AI 应用普及融资热潮出现。

3. **应用型 Agent 赛道**

· 核心特征：从 “对话” 向 “思考 - 行动” 范式转变，深度集成企业业务流程，提供端到端自动化解决方案，如 Sierra AI 的客户服务、退订管理等场景应用。

· 商业模式：创新定价，如 Sierra 按对话量或成功解决案例数量计费，与企业客户价值绑定，颠覆传统 SaaS 按席位收费模式；通过多模型协同 “星座架构” 整合顶级模型，直连企业系统构建决策闭环，技术壁垒高。

4. **赛道关系**：相互依存、协同演进，基础模型为工具链和 Agent 提供底层能力，工具链加速应用开发，Agent 实践反馈需求与数据优化基础模型和工具链；Sierra AI 验证 “数字化员工” 规模化路径，AI 价值创造向应用层迁移。

5. **赛道挑战**：前沿基础模型面临算力成本、能源消耗、伦理对齐问题；AI 工具链需平衡兼容性、易用性、性能；应用型 Agent 需优化复杂场景可靠性、模型幻觉控制、系统集成深度；Sierra AI 需应对模型依赖风险、数据飞轮构建、伦理防御问题。

## **五、技术前沿**

### **5.1 Evolving Prompts In-Context: LLM 对语义的依赖比我们想象的少**

1. **论文基础**：Jianyu Wang、Zhiqiang Hu、Lidong Bing 合作论文《Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective》，颠覆传统 LLM 提示设计范式，挑战 “精心设计指令和演示示例最优” 共识，发现修剪自然语言提示为 “乱码” 可提升模型表现。

2. **核心发现**：“乱码” 提示跨模型普适，与模型对齐状态无关，多项任务匹配甚至超越先进自动提示优化技术；提出 PROMPTQUINE 框架，采用进化搜索算法，利用上下文 token 资源自主发现修剪策略，模拟生物进化自复制和适应机制。

3. **技术实现**：将提示优化重构为引导式搜索，搜索空间为原始提示所有可能子序列，动态调整长度优化目标函数；设计基于遗传算法搜索机制，二进制 token 掩码为基因型，ICL 提示为表现型，位翻转变异，精英选择优化后代。

4. **实验结果**：覆盖分类、多选题、生成、数学推理等任务，分类任务中 SST-2 情感分析准确率 96.2%、AG’s 新闻分类 89.2%，优于传统 ICL；数学推理 GSM8K 任务 1-shot 提示准确率 77.1%，接近 8-shot 标准提示 78.5%，token 长度缩减 97%。

5. **机理分析**：修剪后提示标签词保留率高，与传统 ICL 认知一致；但随机标签词初始化仍能提升性能，70B 模型接近任务直觉标签词水平，表明 LLM 可能仅表面对齐人类语言，内部推理依赖特定特征而非显式语言结构。

6. **应用价值与意义**

· 对齐挑战：经红队测试模型仍可能被非常规提示诱导恶意行为，建议探索本质内在对齐方法。

· 部署价值：PROMPTQUINE 在 A100 GPU 数分钟完成提示优化，快于传统 RLPrompt 的 12 小时。

· 研究意义：揭示 LLM 理解机制局限，呼吁重新审视上下文学习本质，推动从 “人类语言空间” 向 “LLM 语言空间” 范式转变。

## **六、风险提示**

· 以上内容基于历史数据完成，政策、市场环境变化时存在失效风险；历史信息不代表未来。

· 市场有风险，投资需谨慎。
